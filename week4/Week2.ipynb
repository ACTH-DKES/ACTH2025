{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFDiZxgUo9mFxSTxBLnKhB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACTH-DKES/ACTH2025/blob/main/Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises Week 1\n",
        "\n",
        "## Text To tuples"
      ],
      "metadata": {
        "id": "NldiZyKKS1BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tuples(sentence, integer):\n",
        "    result = []\n",
        "    words = sentence.split()\n",
        "    number_of_divisions = len(words)//integer\n",
        "    if len(words) % integer != 0:\n",
        "        number_of_divisions += 1\n",
        "    words.reverse()\n",
        "    for i in range(number_of_divisions):\n",
        "        temp_list = []\n",
        "        for i in range(integer):\n",
        "            if len(words) != 0:\n",
        "                temp_list.append(words.pop())\n",
        "        result.append(tuple(temp_list))\n",
        "    return result\n",
        "\n",
        "\n",
        "text_to_tuples(\"Hi My Life Is So Great After Programming\", 3)\n"
      ],
      "metadata": {
        "id": "1UQKbfP5S7w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A dictionary of operations"
      ],
      "metadata": {
        "id": "anF9_NhpVbgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import write\n",
        "import csv\n",
        "def dictionary_of_operations(dictionary):\n",
        "    if len(dictionary[\"numbers1\"]) != len(dictionary[\"numbers2\"]) and \\\n",
        "        len(dictionary[\"numbers1\"]) != len(dictionary[\"operations\"]):\n",
        "            print(\"Invalid input\")\n",
        "            return None\n",
        "    with open(\"result.csv\", \"w\") as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"Number1\", \"Number2\", \"Operation\", \"Result\"])\n",
        "        for i, el in enumerate(dictionary[\"numbers1\"]):\n",
        "            if dictionary[\"operations\"][i] == \"sum\":\n",
        "                writer.writerow([el,dictionary[\"numbers2\"][i],\n",
        "                                 dictionary[\"operations\"][i],\n",
        "                                 el + dictionary[\"numbers2\"][i]])\n",
        "            elif dictionary[\"operations\"][i] == \"sub\":\n",
        "                writer.writerow([el,dictionary[\"numbers2\"][i],\n",
        "                                 dictionary[\"operations\"][i],\n",
        "                                 el - dictionary[\"numbers2\"][i]])\n",
        "            elif dictionary[\"operations\"][i] == \"mult\":\n",
        "                writer.writerow([el,dictionary[\"numbers2\"][i],\n",
        "                                 dictionary[\"operations\"][i],\n",
        "                                 el * dictionary[\"numbers2\"][i]])\n",
        "            elif dictionary[\"operations\"][i] == \"div\":\n",
        "                writer.writerow([el,dictionary[\"numbers2\"][i],\n",
        "                                 dictionary[\"operations\"][i],\n",
        "                                 el / dictionary[\"numbers2\"][i]])\n",
        "            else:\n",
        "                print(\"Invalid operation\")\n",
        "                return None\n",
        "\n",
        "example_dictionary = {\"numbers1\":[2,4,5.9,10], \"numbers2\":[12,9,10,11],\n",
        "                      \"operations\":[\"sum\", \"sub\", \"mult\", \"div\"]}\n",
        "dictionary_of_operations(example_dictionary)"
      ],
      "metadata": {
        "id": "UspbJzIAVa0F"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 2 - Pandas and Statistical Analysis in Humanities: handling real-world data\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Met Museum Collection Metadata (5000 artworks sample)\n",
        "\n",
        "`met_museum_5000_sample.csv`\n",
        "\n",
        "## Libraries we will use today\n",
        "### pandas\n",
        "* Use: Data manipulation and analysis.\n",
        "* Key functionalities:\n",
        "    * Data structures: DataFrame, Series.\n",
        "    * Data handling: loading, filtering, grouping, aggregating, pivoting.\n",
        "    * Basic visualization.\n",
        "\n",
        "[Documentation](https://pandas.pydata.org/docs/)\n",
        "\n",
        "\n",
        "### scipy\n",
        "* Use: Advanced scientific computing.\n",
        "* Key functionalities:\n",
        "    * Statistical testing (t-tests, ANOVA, correlation).\n",
        "    * Scientific algorithms and computations.\n",
        "\n",
        "[Documentation](https://docs.scipy.org/doc/scipy/)\n",
        "\n",
        "### spacy\n",
        "* Use: Natural Language Processing\n",
        "* Key Functionalities:\n",
        "    * Named Entity Recognition (NER)\n",
        "    * part of speech (POS) tagging\n",
        "    * linguistic analysis\n",
        "\n",
        "[Documentation](https://spacy.io/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JK1UF8wYudwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import pandas and Load the Data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q8WYUCC_xr6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df = pd.read_csv('met_museum_5000_sample.csv')\n",
        "\n",
        "# Inspect the first few rows to get an initial understanding\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "10QBMEy0xwJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* pandas is imported as pd conventionally\n",
        "* `.read_csv()` loads data into a structured table-like form (`DataFrame`)\n",
        "* `.head()` is used to display the first rows of a DataFrame"
      ],
      "metadata": {
        "id": "e0g9AHpLx4Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnShWF7KyLab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Examine Data Structure"
      ],
      "metadata": {
        "id": "mLwRDR8k4iEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get information on columns, datatypes, and non-NaN or null counts\n",
        "df.info()\n",
        "\n",
        "# Get basic statistical descriptions (numeric columns)\n",
        "df.describe(include='all')\n"
      ],
      "metadata": {
        "id": "aSmDW9xM4jbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `.info()` summarizes column names, data types, and null-value counts.\n",
        "* `.describe()` gives descriptive statistics: mean, median, standard deviation, quartiles for numeric columns, and top/frequency for categorical columns."
      ],
      "metadata": {
        "id": "egyBEpJC5xXC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kaFXRZh366Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Selecting Specific Data"
      ],
      "metadata": {
        "id": "mQOKoT-b-eKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select specific columns (Artist Display Name, Title, Object Name)\n",
        "selected_df = df[['Artist Display Name', 'Title', 'Object Name']]\n",
        "\n",
        "# Filter rows where objects are specifically 'Paintings'\n",
        "paintings_df = df[df['Object Name'] == 'Painting']\n",
        "paintings_df.head()"
      ],
      "metadata": {
        "id": "orbDRNVB-hsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1exhWugb_jXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Checking Missing Data\n",
        "\n",
        "CH Datasets often have incomplete information"
      ],
      "metadata": {
        "id": "aLDCOEdd_ra6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values per column\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Lrq99v_e_5j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in 'Artist Display Name'\n",
        "\n",
        "df['Artist Display Name'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "4gLrT25r_5-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `.isnull().sum()` identifies gaps in data quality.\n",
        "\n",
        "* `.fillna()` replaces missing data to maintain consistency in analysis."
      ],
      "metadata": {
        "id": "tjSZT2ayANnV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ws_MQ9ZaAcUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Grouping and Counting"
      ],
      "metadata": {
        "id": "FFGilRurAdIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count artworks per nationality\n",
        "nationality_counts = df['Artist Nationality'].value_counts()\n",
        "nationality_counts.head(10)"
      ],
      "metadata": {
        "id": "KGttzpWzCihd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is that \"|\"? Is that how the dataset deals with multiple elements in the\n",
        "# Same cell? How can we fix that?\n",
        "\n",
        "nationality_counts = \\\n",
        "df['Artist Nationality'].dropna().str.split('|').explode().str.strip().value_counts()\n",
        "nationality_counts.head(10)\n"
      ],
      "metadata": {
        "id": "MhkUL8VUCjYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty values?\n",
        "nationality_counts = \\\n",
        "df['Artist Nationality'].dropna().str.split('|').explode().str.strip()\n",
        "# Select only the nationality that are not \"\"\n",
        "nationality_counts = nationality_counts[nationality_counts != \"\"].value_counts()\n",
        "nationality_counts.head(10)\n"
      ],
      "metadata": {
        "id": "31XBPznzEBMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `str.split('|')` splits the cell at every \"|\".\n",
        "* `explode()` transforms each element of a list into its own row.\n",
        "* `.str.strip()` cleans whitespace around names.\n",
        "* `.value_counts()` summarizes the frequency of each category."
      ],
      "metadata": {
        "id": "nDGBxtULE9QX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spe5OloJFtIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Quick Visualization in Pandas"
      ],
      "metadata": {
        "id": "K_MhfQ8VFtwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple plot of the top 10 artist nationalities\n",
        "nationality_counts.head(10).plot(kind='bar',\n",
        "                                 title='Top 10 Artist Nationalities in MET')"
      ],
      "metadata": {
        "id": "7RUPULJeFzcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nationality_counts.head(10).plot(kind='pie',\n",
        "                                 title='Top 10 Artist Nationalities in MET')"
      ],
      "metadata": {
        "id": "D6R9LZFUF1KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkXGESN5GELI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Date Cnversion and Cleanup\n",
        "Dates in CH datasets could be tricky, and must be standardized"
      ],
      "metadata": {
        "id": "bTQcpkKwGSG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Object Begin Date to numeric\n",
        "df['New Object Begin Date'] = pd.to_numeric(df['Object Begin Date'], errors='coerce')\n",
        "\n",
        "# Check date statistics\n",
        "df['New Object Begin Date'].describe()"
      ],
      "metadata": {
        "id": "A8vEDnDmGWXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `pd.to_numeric()` converts values to numeric type, replacing non-numeric entries with NaNs for further statistical analysis."
      ],
      "metadata": {
        "id": "ruJYvN83GmAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Filtering by Date"
      ],
      "metadata": {
        "id": "7Dhk24TrGuTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select artworks from 1800-1900\n",
        "\n",
        "art_19th_century = df[(df['New Object Begin Date'] >= 1800) &\n",
        "                      (df['New Object Begin Date'] <= 1900)]\n",
        "art_19th_century.head()"
      ],
      "metadata": {
        "id": "0Er5rie-GfVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Aggregating different values"
      ],
      "metadata": {
        "id": "Xo03FV4hLBuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean conditions filter data according to a historical period."
      ],
      "metadata": {
        "id": "YcL-U9FHHG6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean, median, and counts for dates grouped by classification\n",
        "classification_stats = df.groupby('Classification')['New Object Begin Date'].agg(['mean', 'median', 'count'])\n",
        "classification_stats.sort_values(by='count', ascending=False).head()"
      ],
      "metadata": {
        "id": "DBywis87IDod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem, there is still this multi-value for cells, let's find a solution"
      ],
      "metadata": {
        "id": "qVxHmJ3BJ9E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Expand the Classification values into individual rows\n",
        "df_classifications = df[['Classification', 'New Object Begin Date']].dropna().copy()\n",
        "df_classifications['Classification'] = df_classifications['Classification'].str.split('|')\n",
        "\n",
        "# Step 2: Explode to have one classification per row\n",
        "df_exploded = df_classifications.explode('Classification')\n",
        "df_exploded['Classification'] = df_exploded['Classification'].str.strip()\n",
        "\n",
        "# Step 3: Aggregate mean, median, and counts by Classification\n",
        "classification_stats = (\n",
        "    df_exploded\n",
        "    .groupby('Classification')['New Object Begin Date']\n",
        "    .agg(['mean', 'median', 'count'])\n",
        "    .sort_values(by='count', ascending=False)\n",
        ")\n",
        "\n",
        "# Display the top 10 classifications\n",
        "classification_stats.head(10)\n"
      ],
      "metadata": {
        "id": "WaY053e6IYk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hcnNjqztJLx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why Copy?\n",
        "\n",
        "Without .copy(), the resulting DataFrame (df_classification) may just be a \"view\" of the original DataFrame (df). This means changes made to df_classification could inadvertently affect df, and vice versa.\n"
      ],
      "metadata": {
        "id": "Mo4xA5ySLQx7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rP-zIslFLaWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 11: Statistical Analysis T test - Hypothesis Testing\n",
        "\n",
        "A t-test is a statistical hypothesis test used to determine if there's a significant difference between the means (averages) of two groups.\n",
        "\n",
        "In simple terms, a t-test answers the question:\n",
        "\n",
        "\"Are these two groups different enough that the difference is unlikely to have occurred by random chance alone?\"\n",
        "\n",
        "It Helps you determine whether observed differences between groups are meaningful or just random noise. It is Commonly used across sciences (humanities included) to assess experimental results, comparative analyses, or surveys.\n",
        "\n",
        "The T-stat is the magnitude of the difference, it will be > 0 if the average of element1 is superior to element2. It will be < 0 if the average of the element2 is superior to element1. The further away it is from 0, the greater the difference.\n",
        "\n",
        "The p-value of the T-test is used to verify whether the difference is statistically significant or not.\n",
        "\n",
        "Usually, less than 0.05 is statistically significant. More than that could sugges that the observed difference might be due to random chance.\n",
        "\n",
        "Let's use a t-test to compare whether American and French Artists' average creation dates differ **significantly**\n",
        "\n"
      ],
      "metadata": {
        "id": "CaS2iG-HLv8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Step 1: Expand multiple nationalities into separate rows\n",
        "df_nationality = df[['Artist Nationality', 'New Object Begin Date']].dropna().copy()\n",
        "df_nationality['Artist Nationality'] = df_nationality['Artist Nationality'].str.split('|')\n",
        "\n",
        "# Explode into individual nationality rows\n",
        "df_nationality = df_nationality.explode('Artist Nationality')\n",
        "df_nationality['Artist Nationality'] = df_nationality['Artist Nationality'].str.strip()\n",
        "\n",
        "# Step 2: Filter explicitly for American and French artists\n",
        "american_dates = df_nationality[\n",
        "    df_nationality['Artist Nationality'] == 'American'\n",
        "]['New Object Begin Date'].dropna()\n",
        "\n",
        "french_dates = df_nationality[\n",
        "    df_nationality['Artist Nationality'] == 'French'\n",
        "]['New Object Begin Date'].dropna()\n",
        "\n",
        "# Step 3: Perform the statistical test (T-test)\n",
        "t_stat, p_value = ttest_ind(american_dates, french_dates, equal_var=False)\n",
        "\n",
        "# Results clearly stated\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The difference between American and French artists' dates is statistically significant.\")\n",
        "else:\n",
        "    print(\"The difference between American and French artists' dates is NOT statistically significant.\")\n"
      ],
      "metadata": {
        "id": "vcNlUNiaMWn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A positive t-value means the first group (e.g., American artists)\n",
        "# has a higher mean date than the second group (e.g., French artists).\n",
        "# Because the p value is very small, it means that\n",
        "# the difference between the groups is highly unlikely\n",
        "# to have arisen by random chance alone."
      ],
      "metadata": {
        "id": "g1qsHLyuM055"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQWc1bdqOIz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12: Gender Based Analysis\n",
        "\n",
        "Let's explore how gender is described in the dataset"
      ],
      "metadata": {
        "id": "731XR3gYOJTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "KOYJ0BKbOWZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Artist Gender'].unique()"
      ],
      "metadata": {
        "id": "CtNMZqb_OXL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only females? Could it be that the Empty values are for non-Female artists?"
      ],
      "metadata": {
        "id": "K2j3DVsSOduB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Artist Display Name']"
      ],
      "metadata": {
        "id": "7TkTkdWaObAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From this small view, we can see that there seem to be non-Female and\n",
        "# Institutions\n",
        "# We need to assign the correct gender (or institution) instead of leaving\n",
        "# it empty\n",
        "# We hypothesize that all the empty values are either non-Female or\n",
        "# Institutions\n",
        "# How do we distinguish between the two?\n",
        "# Given that there are empty values, can we make sure that they match\n",
        "# with the number of artists or are there mistakes in the data?"
      ],
      "metadata": {
        "id": "9v_92lsUOtoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Mistakes"
      ],
      "metadata": {
        "id": "bZSlkn44PWdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count the number of values separated by \"|\"\n",
        "def count_splits(value):\n",
        "    if pd.isna(value): # checks if the values is NaN\n",
        "        return 0\n",
        "    return len(str(value).split('|'))\n",
        "\n",
        "# Count artists and gender entries\n",
        "df['Artist_Count'] = df['Artist Display Name'].apply(count_splits)\n",
        "df['Gender_Count'] = df['Artist Gender'].apply(count_splits)\n",
        "# Apply is used to apply a function to a part of a dataframe\n",
        "# Adjusted mismatch logic\n",
        "def check_mismatch(row):\n",
        "    # Rule: Single artist with NaN gender is NOT a mismatch\n",
        "    if row['Artist_Count'] == 1 and pd.isna(row['Artist Gender']):\n",
        "        return False  # no mismatch\n",
        "    return row['Artist_Count'] != row['Gender_Count']\n",
        "\n",
        "# Apply this logic\n",
        "df['Mismatch'] = df.apply(check_mismatch, axis=1) # Axis 1 because we\n",
        "# are working\n",
        "# rowise non column wise\n",
        "\n",
        "# Now examine the mismatches\n",
        "mismatches = df[df['Mismatch']]\n",
        "\n",
        "print(f\"Total mismatches (after correction): {len(mismatches)}\")\n"
      ],
      "metadata": {
        "id": "RJ2DrZyrPYri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No mistakes, we are lucky!"
      ],
      "metadata": {
        "id": "wtCG__g2PepZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER Named Entity Recognition to distinguish between people and institutions\n",
        "\n",
        "Rationale:\n",
        "\n",
        "* If gender is explicitly marked \"Female\", preserve as \"Female\".\n",
        "\n",
        "* If gender is missing or empty:\n",
        "\n",
        "    * Perform NER:\n",
        "\n",
        "        * Label entities as \"Institution\" if NER detects organizations.\n",
        "\n",
        "        * Label entities as \"Non-Female\" if NER detects people but gender not marked explicitly.\n",
        "\n",
        "        * Label entities as \"Unknown\" otherwise or if Spacy detects both"
      ],
      "metadata": {
        "id": "S_c9PTP-PBsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy's NER model\n",
        "# might be necessary to !pip install spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def classify_artists(names, genders):\n",
        "    names_list = str(names).split('|')\n",
        "    # Handle NaN genders correctly: generate empty list if NaN\n",
        "    genders_list = str(genders).split('|') if pd.notna(genders) else [''] * len(names_list)\n",
        "\n",
        "    # Correct potential length mismatches by padding\n",
        "    if len(genders_list) < len(names_list):\n",
        "        genders_list += [''] * (len(names_list) - len(genders_list))\n",
        "\n",
        "    corrected_genders = []\n",
        "    for name, gender in zip(names_list, genders_list):\n",
        "        name_clean = name.strip()\n",
        "        gender_clean = gender.strip()\n",
        "\n",
        "        if gender_clean == 'Female':\n",
        "            corrected_genders.append('Female')\n",
        "        else:\n",
        "            # Run NER on names without explicit 'Female' gender\n",
        "            doc = nlp(name_clean)\n",
        "            entity_labels = [ent.label_ for ent in doc.ents]\n",
        "\n",
        "            if 'ORG' in entity_labels and 'PERSON' in entity_labels:\n",
        "                corrected_genders.append('Unknown')\n",
        "            elif 'ORG' in entity_labels:\n",
        "                corrected_genders.append('Institution')\n",
        "            elif 'PERSON' in entity_labels:\n",
        "                corrected_genders.append('Non-Female')\n",
        "            else:\n",
        "                corrected_genders.append('Unknown')\n",
        "\n",
        "    return '|'.join(corrected_genders)\n",
        "\n",
        "# Single-artist with NaN gender handled correctly:\n",
        "def apply_classification(row):\n",
        "    if row['Artist_Count'] == 1 and pd.isna(row['Artist Gender']):\n",
        "        return classify_artists(row['Artist Display Name'],\n",
        "                                row['Artist Gender'])\n",
        "    else:\n",
        "        return classify_artists(row['Artist Display Name'],\n",
        "                                row['Artist Gender'])\n",
        "\n",
        "df['Corrected_Gender'] = df.apply(apply_classification, axis=1)\n"
      ],
      "metadata": {
        "id": "grWZix17PFQ3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Corrected_Gender'].unique()"
      ],
      "metadata": {
        "id": "eKrQdmrKba6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = \"Bryan\"\n",
        "test2 = \"Prince Williams of the LMU University\"\n",
        "doc = nlp(test2)"
      ],
      "metadata": {
        "id": "1ae-E5sLY2LQ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for el in doc.ents:\n",
        "    print(el.label_)\n",
        "# test other things while iterating over doc:\n",
        "'''token.text: The original text of the token.\n",
        "token.lemma_: The base form of the word (e.g., \"running\" -> \"run\").\n",
        "token.pos_: The part-of-speech tag (e.g., \"NOUN\", \"VERB\", \"ADJ\").\n",
        "token.tag_: A more detailed part-of-speech tag.\n",
        "token.dep_: The dependency relationship to other words in the sentence.\n",
        "token.is_stop: Whether the token is a common stop word (like \"the\", \"a\", \"is\").\n",
        "token.is_alpha: Whether the token is alphabetic.\n",
        "token.is_punct: Whether the token is punctuation.'''\n",
        "#for el in doc:\n",
        "    #print(el.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "oGQ0d-diY-y4",
        "outputId": "7ca0afbf-c8fd-42d5-d211-5869ee7f49de"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERSON\n",
            "ORG\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'token.text: The original text of the token.\\ntoken.lemma_: The base form of the word (e.g., \"running\" -> \"run\").\\ntoken.pos_: The part-of-speech tag (e.g., \"NOUN\", \"VERB\", \"ADJ\").\\ntoken.tag_: A more detailed part-of-speech tag.\\ntoken.dep_: The dependency relationship to other words in the sentence.\\ntoken.is_stop: Whether the token is a common stop word (like \"the\", \"a\", \"is\").\\ntoken.is_alpha: Whether the token is alphabetic.\\ntoken.is_punct: Whether the token is punctuation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Corrected_Gender\"].unique()"
      ],
      "metadata": {
        "id": "1AZYCCaaQWNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Jp5dzF5QnzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise (At home)\n",
        "\n",
        "Create a bar plot of the gender distribution in the dataframe after the correction\n",
        "\n",
        "<details>\n",
        "    <summary>Solution</summary>\n",
        "\n",
        "    corrected_gender_series = df['Corrected_Gender'].str.split('|').explode()\n",
        "    gender_counts = corrected_gender_series.value_counts()\n",
        "    gender_counts.plot(kind='bar', title='Corrected Gender Distribution')\n",
        "</details>"
      ],
      "metadata": {
        "id": "TaPO0s6QRSCP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I08ueG87RDar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4LIs8JJiRj7p"
      }
    }
  ]
}