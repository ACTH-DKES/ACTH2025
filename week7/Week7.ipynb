{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/H38YPOE2ZArsKO5Tme9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACTH-DKES/ACTH2025/blob/main/week7/Week7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning in the Humanities\n",
        "\n",
        "Machine Learning (ML) is a field of computer science that enables computers to learn patterns from data and make **predictions** or decisions without being explicitly programmed for each task. **The results are estimations, we can rarely completely rely on them 100%.**\n",
        "\n",
        "In the humanities, ML can help us:\n",
        "- Group artworks by stylistic similarities\n",
        "- Discover hidden themes or topics in text\n",
        "- Classify objects based on metadata\n",
        "- Generate recommendations or analogies\n",
        "\n",
        "We will first explore three text ML tasks using the MET Open Access dataset:\n",
        "1. **Text Classification**\n",
        "2. **Clustering**\n",
        "3. **Topic Modeling**\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "### Training, Validation, and Test Sets\n",
        "- **Training Set**: Used to train the model (learn patterns)\n",
        "- **Validation Set**: (optional) Tune model parameters\n",
        "- **Test Set**: Evaluate model on unseen data\n",
        "\n",
        "### Evaluation Metrics\n",
        "- **Accuracy**: % of correct predictions\n",
        "- **Precision/Recall/F1**: We know the formulas\n",
        "- **Confusion Matrix**: Breakdown of true vs. predicted classes\n",
        "\n",
        "### Supervised vs. Unsupervised Learning\n",
        "- **Supervised Learning**: Learn from labeled data (e.g., classify artwork type from description)\n",
        "- **Unsupervised Learning**: Find structure in unlabeled data (e.g., group similar descriptions)\n"
      ],
      "metadata": {
        "id": "2zMGdRkxwOCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the following Python libraries:\n",
        "\n",
        "- **pandas**: you know\n",
        "- **scikit-learn** (`sklearn`): Machine learning tools\n",
        "- **nltk** or **spaCy**: Text preprocessing\n",
        "- **matplotlib / seaborn**: Visualization"
      ],
      "metadata": {
        "id": "qM7WCzjQwtjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (if needed)\n",
        "#!pip install pandas scikit-learn matplotlib seaborn nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA, NMF\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "eaa99GHWkHhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_filt15k = pd.read_csv(\"https://raw.githubusercontent.com/ACTH-DKES/ACTH2025/refs/heads/main/week7/filteredCleveland15k.csv\")\n",
        "\n",
        "df_filt15k = df_filt15k.drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "FZPdp_UxjLWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # regex to remove non alphanumeric ch\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df_filt15k[\"clean_description\"] = df_filt15k[\"description\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "V-y_w3D72DXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filt15k.head()"
      ],
      "metadata": {
        "id": "EgC12q_E2ZCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification\n",
        "\n",
        "We'll use **TF-IDF** (Term Frequency-Inverse Document Frequency) to transform text into numerical vectors, and train a **Logistic Regression** model to predict the `Object Name` based on the description.\n",
        "\n",
        "This is a **supervised learning** task.\n",
        "\n",
        "TF-IDF = Term Frequency * Inverse Document Frequency. It weights words that are frequent in a document but rare across the corpus, giving more importance to informative terms.\n",
        "\n",
        "### Logistic Regression\n",
        "\n",
        "**Logistic Regression** is a supervised machine learning algorithm used for **classification tasks**. Despite its name, it is not used for regression.\n",
        "\n",
        "#### What It Does\n",
        "Logistic Regression models the **probability** that a given input belongs to a particular class.\n",
        "\n",
        "- For **binary classification**, it outputs a value between 0 and 1 using the **sigmoid function**:\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "  This value is interpreted as the probability of belonging to the positive class.\n",
        "\n",
        "- For **multiclass classification**, it uses the **softmax function** to assign probabilities across all classes.\n",
        "\n",
        "#### Why Use It\n",
        "- Simple and computationally efficient\n",
        "- Performs well with high-dimensional data (such as text represented by TF-IDF vectors)\n",
        "- Provides interpretable probability outputs\n",
        "- Includes built-in regularization options to help prevent overfitting\n",
        "\n",
        "TLDR: **Logistic Regression** is used as a baseline for classification problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "kVsebteR3AVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification task\n",
        "\n",
        "We want to **predict the `type`** (e.g., \"Bowl\", \"Painting\", \"Sword\") from the cleaned description.\n",
        "\n",
        "To do this:\n",
        "1. Convert text to numerical features using **TF-IDF**\n",
        "2. Train a **Logistic Regression** classifier\n",
        "3. Evaluate the model\n",
        "\n",
        "We limit the number of features to 3000 for efficiency and to avoid overfitting using:\n",
        "```python\n",
        "TfidfVectorizer(max_features=3000)\n",
        "```\n",
        "### More info on Overfitting: When the Model Knows Too Much\n",
        "\n",
        "**Overfitting** happens when a machine learning model performs very well on the training data but poorly on unseen data. This means the model has \"memorized\" the training set rather than learned general patterns.\n",
        "\n",
        "#### Symptoms of Overfitting:\n",
        "- Very high accuracy on the training set\n",
        "- Much lower accuracy on the test set\n",
        "- Unusual or overconfident predictions\n",
        "\n",
        "#### Why Does Overfitting Happen?\n",
        "- The model is too complex for the amount of data (e.g. too many parameters or features)\n",
        "- The training set contains noise or biases that the model learns\n",
        "- The dataset is small or not representative\n",
        "\n",
        "#### How to Avoid Overfitting:\n",
        "- Use **simpler models** (e.g., fewer TF-IDF features with `max_features`)\n",
        "- **Split your data** into training/test sets (we use `test_size=0.2` for this)\n",
        "- Apply **regularization** (Logistic Regression does this by default)\n",
        "- Get **more data** (hard in the humanities, but ideal)\n"
      ],
      "metadata": {
        "id": "fXHlqoXv36RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=3000)  # Keep top 3000 terms\n",
        "X = tfidf.fit_transform(df_filt15k[\"clean_description\"])  # Fit and transform: learn vocab + transform text to vector\n",
        "y = df_filt15k[\"type\"]\n",
        "\n",
        "# Drop rare classes to reduce noise\n",
        "counts = y.value_counts()\n",
        "keep_labels = counts[counts > 30].index  # Keep classes with >30 instances\n",
        "\n",
        "# Convert boolean Series to numpy array for indexing sparse matrix\n",
        "filter_mask = y.isin(keep_labels).to_numpy()\n",
        "X = X[filter_mask]\n",
        "y = y[y.isin(keep_labels)]\n",
        "\n",
        "\n",
        "# Split data: 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "# test_size=0.2 means 20% of the data will be used for testing\n",
        "# random state: reproduciblity, it will always split it in the same way\n",
        "\n",
        "# Train classifier\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)  # Fit = train the model on (X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test)  # Predict = generate output for unseen test data\n",
        "\n",
        "# Report\n",
        "print(classification_report(y_test, y_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "mCAQif1U4ek8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_desc = \"A lady with a rose depicted with strong blush and vivid colors, printed by London Inc Press\"\n",
        "cleaned = clean_text(new_desc)\n",
        "X_new = tfidf.transform([cleaned])  # Note: we use transform, not fit_transform\n",
        "prediction = clf.predict(X_new)\n",
        "print(\"Predicted Object Name:\", prediction[0])\n",
        "#.fit_transform() is only used during training.\n",
        "#.transform() ensures new data is converted using the existing vocabulary and weights."
      ],
      "metadata": {
        "id": "Z_Hc2xiw8jtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = clf.predict_proba(X_new)\n",
        "class_probs = pd.Series(probs[0], index=clf.classes_).sort_values(ascending=False)\n",
        "print(class_probs.head())"
      ],
      "metadata": {
        "id": "SIbgS61p-qO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: predictive function\n",
        "\n",
        "Develop the function\n",
        "`predict_label(description, vectorizer, model, clean_f, prob = False)`\n",
        "that (i) takes as input a description, a vectorizer, a trained model, a cleaning function, and a Boolean (prob) which is False by default and (ii) returns the predicted class from the model if prob is False, otherwise it returns the top 5 probable classes if prob is True.\n",
        "\n",
        "Test it with the current vectorizer, trained model and cleaning function written before in the notebook.\n",
        "\n",
        "<details> <summary>Solution</summary>\n",
        "<pre>\n",
        "def predict_label(description, vectorizer, model, clean_f, prob = False):\n",
        "    cleaned = clean_f(description)\n",
        "    X_new = vectorizer.transform([cleaned])\n",
        "    if prob:\n",
        "        probs = model.predict_proba(X_new)\n",
        "        class_probs = pd.Series(probs[0], index=model.classes_).sort_values(ascending=False)\n",
        "        return class_probs.head()\n",
        "    else:\n",
        "        prediction = model.predict(X_new)\n",
        "        return prediction[0]\n",
        "\n",
        "predict_label(\"This photograph represents Mount Fuji snowing\", tfidf, clf, clean_text, True)\n",
        "</pre>\n",
        "</details>"
      ],
      "metadata": {
        "id": "KvXOB9l9mOoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check overfitting\n",
        "\n",
        "If the accuracy in the training is very high but it is low in the test set, it means the model is overfitting (i.e., it learns just the patterns of known data but it struggles with new data)"
      ],
      "metadata": {
        "id": "sCewQ0EHpSfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict on the training data\n",
        "y_train_pred = clf.predict(X_train)\n",
        "\n",
        "# Compare predictions to true training labels\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Training Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "id": "dfcDLQS6pWmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "qrOieLnRphW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar([\"Training\", \"Test\"], [train_accuracy, test_accuracy], color=[\"pink\", \"yellow\"])\n",
        "plt.title(\"Training vs Test Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t0fKngxcpnoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "Visualizing how classes are confused by the model"
      ],
      "metadata": {
        "id": "umdtPh0zpQAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
        "cm_df = pd.DataFrame(cm, index=clf.classes_, columns=clf.classes_)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6jeDsEkO4zp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering\n",
        "\n",
        "Clustering is **unsupervised learning** — we don't provide labels. We let the model group similar items based on their TF-IDF vectors.\n",
        "\n",
        "We use:\n",
        "- **KMeans**: Standard clustering algorithm. We set `n_clusters=5` to force 5 groups.\n",
        "- **PCA**: Principal Component Analysis reduces high-dimensional vectors to 2D for visualization.\n",
        "\n",
        "`.fit_predict()`\n",
        "- `.fit_predict()` fits the KMeans model and returns the cluster each item belongs to.\n"
      ],
      "metadata": {
        "id": "-3Z6JIg-AJ2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run KMeans clustering\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "clusters = kmeans.fit_predict(X)\n",
        "\n",
        "# Reduce dimensionality for plotting\n",
        "pca = PCA(n_components=2)\n",
        "X_reduced = pca.fit_transform(X.toarray())  # Convert sparse to dense for PCA\n",
        "\n",
        "# Build a DataFrame for plotting\n",
        "df_plot = pd.DataFrame({\n",
        "    \"x\": X_reduced[:, 0],\n",
        "    \"y\": X_reduced[:, 1],\n",
        "    \"cluster\": clusters\n",
        "})\n",
        "\n",
        "# Visualize the clusters\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\")\n",
        "plt.title(\"KMeans Clustering of Artwork Descriptions (PCA Projection)\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oW-Q4BIAAIJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clustered = df_filt15k[filter_mask].copy()\n",
        "df_clustered[\"cluster\"] = clusters"
      ],
      "metadata": {
        "id": "vUEw3WtEApzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(kmeans.n_clusters):\n",
        "    print(f\"\\nCluster {i} — {df_clustered[df_clustered['cluster'] == i].shape[0]} artworks\")\n",
        "    #print(df_clustered[df_clustered[\"cluster\"] == i][[\"title\", \"type\", \"clean_description\"]].head(5))"
      ],
      "metadata": {
        "id": "yn3g-Ry36V2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clustered[df_clustered[\"cluster\"] == 3][\"description\"]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IcgNRSN7BRIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More machine learning? look at the sklearn library docs: https://scikit-learn.org/stable/"
      ],
      "metadata": {
        "id": "7YTYwLTbt7Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning on the visual aspects\n",
        "\n",
        "\n",
        "We’ll use a combination of libraries:\n",
        "\n",
        "- **Pandas**: for data handling\n",
        "- **NumPy**: for matrix operations\n",
        "- **Matplotlib**: for visualizations\n",
        "- **Requests**: to fetch images from URLs\n",
        "- **PIL (Pillow)**: to handle image loading and resizing\n",
        "- **TensorFlow / Keras**: to use pre-trained convolutional neural networks (CNNs)\n",
        "- **Scikit-learn (sklearn)**: for clustering (KMeans) and dimensionality reduction (t-SNE)\n",
        "\n",
        "### What is a Convolutional Neural Network (CNN)?\n",
        "A Convolutional Neural Network (CNN) is a type of deep neural network specialized for processing image data. Unlike standard (fully connected) networks, CNNs use convolutional layers that slide small filters over the input image to detect spatial patterns like edges, textures, shapes, and objects.\n",
        "\n",
        "### Keras\n",
        "Keras is a high-level API for building and training deep learning models. It’s part of the TensorFlow ecosystem.\n",
        "It's used to easily define layers, losses, optimizers, and metrics; load pre-trained models from large public datasets (e.g., ImageNet); train and evaluate models on your own data.\n",
        "\n",
        "We use Keras because:\n",
        "\n",
        "It simplifies complex model building.\n",
        "\n",
        "It integrates with TensorFlow in python.\n",
        "\n",
        "It provides many tools for transfer learning (like MobileNetV2, VGG16, etc.).\n",
        "\n",
        "### pre trained model\n",
        "\n",
        "A pre-trained model is a neural network that has already been trained on a large dataset — typically ImageNet (which contains over 14 million images across 1000 categories).\n",
        "\n",
        "Instead of training a CNN from scratch (which requires a lot of data and time), we reuse the early layers of a pre-trained model to extract general-purpose features. This process is known as transfer learning.\n",
        "\n",
        "Two ways we use pre-trained models:\n",
        "\n",
        "1.   Feature Extraction: Freeze all layers and use them as-is\n",
        "2.   Fine-Tuning: Unfreeze some layers and retrain on a smaller dataset to specialize the model for a new task.\n",
        "\n",
        "#### models in keras\n",
        "\n",
        "A model in Keras is the full computational pipeline: from input to output.\n",
        "\n",
        "It consists of layers: Convolutional → Pooling → Dense, etc.\n",
        "\n",
        "It must be compiled with a loss function and an optimizer.\n",
        "\n",
        "It can be trained using `.fit()`, evaluated using `.evaluate()`, and used for prediction using `.predict()`.\n",
        "\n",
        "In our case:\n",
        "\n",
        "The input will be an image tensor (224, 224, 3) (dimension1, dimension2, RGB) this is how many models are pretrained, so we will need to turn our images into this format, just like we turned the texts into tfidf.\n",
        "\n",
        "The output will be a softmax probability distribution over our chosen category.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QY0ceTMixrk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering Images\n",
        "\n",
        "We’ll use the `\"image_web\"` field from the Cleveland dataset, which contains direct URLs to artwork images.\n",
        "\n",
        "Steps:\n",
        "1. Filter the dataset to only entries with valid image URLs\n",
        "2. Sample a subset (e.g. 500–1000) to keep runtime reasonable on Colab"
      ],
      "metadata": {
        "id": "fcAd5W4CzOTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filt15k = df_filt15k.dropna(subset=[\"image_web\"])\n",
        "df_filt15k10 = df_filt15k.sample(n=500, random_state=42)"
      ],
      "metadata": {
        "id": "gYgQreIczMCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and preprocess images\n",
        "\n",
        "Each image will be:\n",
        "- Downloaded via `requests`\n",
        "- Resized to 224×224 (required input size for VGG16)\n",
        "- Converted to a NumPy array (vector)\n",
        "- Normalized using `preprocess_input()` from `keras.applications.vgg16` (because this is a pretrained model, we need to fit our dataset with the preprocess created for this model!)\n",
        "\n",
        "We skip any failed downloads or unreadable images."
      ],
      "metadata": {
        "id": "UJ_OV-Wjzez5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "def load_and_preprocess_image(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        img = img.resize((224, 224))\n",
        "        arr = img_to_array(img)\n",
        "        arr = preprocess_input(arr)  # Normalize with VGG16 preprocessing\n",
        "        return arr\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "images = []\n",
        "valid_indices = []\n",
        "\n",
        "for idx, url in tqdm(enumerate(df_filt15k10[\"image_web\"])):\n",
        "    img = load_and_preprocess_image(url)\n",
        "    if img is not None:\n",
        "        images.append(img)\n",
        "        valid_indices.append(idx)\n",
        "\n",
        "images = np.array(images)\n",
        "df_filt15k10 = df_filt15k10.iloc[valid_indices].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "_Zd_vt0rzcYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "id": "sxk_2hLXz1zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('images.pickle', 'wb') as handle:\n",
        "    pickle.dump(images, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "R2FJdAq91KnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('images.pickle', 'rb') as handle:\n",
        "    images = pickle.load(handle)"
      ],
      "metadata": {
        "id": "I7TOZ3QS2NA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## The file was too big for github: https://gigamove.rwth-aachen.de/en/download/373880ad2e3f1d7ff454a8826540ad27/password"
      ],
      "metadata": {
        "id": "ylt8pMdx3SLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction with VGG16\n",
        "\n",
        "We use a **pre-trained VGG16 model** from Keras:\n",
        "- Trained on ImageNet (over 1 million images)\n",
        "- We exclude the top classification layers (`include_top=False`)\n",
        "- Output: a 7×7×512 feature map per image\n",
        "\n",
        "We then flatten these into 1D feature vectors.\n",
        "\n",
        "### Why is the VGG16 Output Shape `(n_images, 7, 7, 512)`?\n",
        "\n",
        "When we pass images through the **VGG16** model (with `include_top=False`), we get feature maps with shape:\n",
        "(n_images, 7, 7, 512)\n",
        "\n",
        "Remember, input is\n",
        "- `224 x 224` = width and height of the image in pixels\n",
        "- `3` = number of color channels (RGB)\n",
        "\n",
        "---\n",
        "\n",
        "#### Architecture of VGG16\n",
        "\n",
        "VGG16 has 13 convolutional layers organized into 5 blocks. Each block ends with a **MaxPooling layer** that reduces the spatial size (width and height) by half.\n",
        "\n",
        "Here’s how the image dimensions change as it goes through the network:\n",
        "\n",
        "| Block | Layers                        | Output Shape         |\n",
        "|-------|-------------------------------|----------------------|\n",
        "| 1     | Conv → Conv → MaxPool         | (112, 112, 64)       |\n",
        "| 2     | Conv → Conv → MaxPool         | (56, 56, 128)        |\n",
        "| 3     | Conv → Conv → Conv → MaxPool  | (28, 28, 256)        |\n",
        "| 4     | Conv → Conv → Conv → MaxPool  | (14, 14, 512)        |\n",
        "| 5     | Conv → Conv → Conv → MaxPool  | (7, 7, 512)          |\n",
        "\n",
        "Each `MaxPool` operation halves the width and height.\n",
        "\n",
        "---\n",
        "\n",
        "#### Final Output\n",
        "\n",
        "After Block 5, the final feature map has the shape:\n",
        "- `7 x 7` = spatial dimensions (small version of original image)\n",
        "- `512` = number of learned filters (pattern detectors)\n",
        "\n",
        "So for a batch of `n_images`, the total output shape is:\n",
        "25088  **because 7 * 7 * 512 = 25088**\n",
        "\n",
        "Each image will be now represented as a 25,088-dimensional feature vector that encodes high-level visual information learned from ImageNet.\n"
      ],
      "metadata": {
        "id": "NjUE60g13TRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the model without the top classification layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Extract features\n",
        "features = base_model.predict(images)  # Output shape: (n_images, 7, 7, 512)\n",
        "features_flat = features.reshape(features.shape[0], -1)  # Flatten: shape (n_images, 25088)"
      ],
      "metadata": {
        "id": "_y1mxoSd4es8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering with KMeans\n",
        "\n",
        "We cluster images based on their visual features:\n",
        "- `n_clusters=5` group images into 5 visual categories\n",
        "- `.fit_predict()` both fits the model and assigns each image to a cluster"
      ],
      "metadata": {
        "id": "Jll4KW2d4ylR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, random_state=0)\n",
        "clusters = kmeans.fit_predict(features_flat)\n",
        "\n",
        "df_filt15k10[\"cluster\"] = clusters"
      ],
      "metadata": {
        "id": "KowQIL_k4ixI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-SNE Visualization\n",
        "\n",
        "To visualize clusters in 2D, we use **t-SNE** (t-distributed stochastic neighbor embedding), a dimensionality reduction technique that preserves local structure.\n",
        "\n",
        "We project each image’s 25,088-dimensional feature vector to 2D.\n",
        "\n",
        "We also use the parameter **Perplexity**\n",
        "\n",
        "---\n",
        "\n",
        "### Perplexity\n",
        "\n",
        "Perplexity controls the balance between local and global structure in the data when projecting it to 2D.\n",
        "\n",
        "A lower perplexity (e.g. 5–10) focuses more on very local structure, meaning small neighborhoods\n",
        "\n",
        "A higher perplexity (e.g. 40–50) preserves broader patterns, meaning more global relationships\n",
        "\n",
        "perplexity=30 is a common default that balances both.\n",
        "\n",
        "---\n",
        "\n",
        "Then, we plot each image as a colored point according to its cluster. Optionally, you can overlay image thumbnails in place of points (see advanced versions).\n",
        "\n",
        "This **SHOULD help** us visually interpret the kinds of images that group together."
      ],
      "metadata": {
        "id": "53Rdbuzi5-za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "coords = tsne.fit_transform(features_flat)\n",
        "\n",
        "df_filt15k10[\"x\"] = coords[:, 0]\n",
        "df_filt15k10[\"y\"] = coords[:, 1]\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "df_filt15k10[\"hover_text\"] = df_filt15k10.apply(\n",
        "    lambda row: f\"Title: {row['title']}<br>Cluster: {row['cluster']}\", axis=1\n",
        ")\n",
        "\n",
        "# Build the interactive scatter plot\n",
        "fig = px.scatter(\n",
        "    df_filt15k10,\n",
        "    x=\"x\", y=\"y\",\n",
        "    color=\"cluster\",\n",
        "    hover_name=\"hover_text\",\n",
        "    hover_data={\"x\": False, \"y\": False, \"cluster\": False},\n",
        "    title=\"Artwork Clusters (t-SNE + VGG16 Features)\",\n",
        "    width=950,\n",
        "    height=750\n",
        ")\n",
        "\n",
        "# Clean hover template — show only custom hover text, no extra info\n",
        "fig.update_traces(hovertemplate=\"%{hovertext}<extra></extra>\")\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ef1UFjgU554n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5piOXbp6sk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect Images by Cluster\n",
        "\n",
        "We can now examine representative samples from each cluster to understand what visual themes/patterns are emerging.\n"
      ],
      "metadata": {
        "id": "JR37nPiJ_nv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image, HTML\n",
        "\n",
        "for cluster_id in sorted(df_filt15k10[\"cluster\"].unique()):\n",
        "    print(f\"\\n### Cluster {cluster_id} samples:\\n\")\n",
        "\n",
        "    # Get the first 3 items from this cluster\n",
        "    cluster_subset = df_filt15k10[df_filt15k10[\"cluster\"] == cluster_id].head(3)\n",
        "\n",
        "    for _, row in cluster_subset.iterrows():\n",
        "        print(f\"Title: {row['title']}\")\n",
        "        print(f\"Type: {row['type']}\")\n",
        "        display(Image(url=row['image_web'], width=200))\n",
        "        print(\"\\n\" + \"*\"*50)\n"
      ],
      "metadata": {
        "id": "z6AhYjUL8Jva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDuwqeJY_uOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning and image classifiers!\n",
        "\n",
        "We’ll build and train a deep learning model to **classify artworks based on their image using transfer learning.**\n",
        "\n",
        "We will use the MobileNetV2 as a base. We will prepare images again according to the new model, and we will fine tune it to predict the type again,we will then evaluate the model performance so we can compare visual and textual results. (Just know, that for text we used 15000 description, and we are only using 450 images because otherwise it would take too long!)\n",
        "\n"
      ],
      "metadata": {
        "id": "ptw-Ffi3ChiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target_col = \"type\"\n",
        "\n",
        "# Only keep top 10 frequent labels for balance and feasibility, because we\n",
        "# do not have a lot of images (compared to the texts we had)\n",
        "top_labels = df_filt15k10[target_col].value_counts().head(10).index.tolist()\n",
        "df_classify = df_filt15k10[df_filt15k10[target_col].isin(top_labels)].copy()\n",
        "\n",
        "print(\"Classes:\", top_labels)\n",
        "print(\"Number of images:\", len(df_classify))"
      ],
      "metadata": {
        "id": "mLsi0rqjDFCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll use Keras’ `ImageDataGenerator` to:\n",
        "\n",
        "Load images directly from URLs again\n",
        "\n",
        "Resize them to (224, 224) again\n",
        "\n",
        "Apply preprocessing compatible with MobileNetV2"
      ],
      "metadata": {
        "id": "h0jy4RNBDjSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Load images and labels\n",
        "images, labels = [], []\n",
        "\n",
        "for _, row in df_classify.iterrows():\n",
        "    try:\n",
        "        response = requests.get(row[\"image_web\"], timeout=5)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        img = img.resize((224, 224))\n",
        "        arr = np.array(img)\n",
        "        arr = preprocess_input(arr)  # MobileNetV2 preprocessing\n",
        "        images.append(arr)\n",
        "        labels.append(row[target_col])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(len(images))"
      ],
      "metadata": {
        "id": "P4bWlWKZDH6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(labels)\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, y_cat, test_size=0.2, stratify=y_cat, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(X_train))\n",
        "print(\"Test samples:\", len(X_test))\n",
        "print(\"Classes:\", le.classes_)\n"
      ],
      "metadata": {
        "id": "JijPkGZdD2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDING THE MODEL!!!\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load base model\n",
        "base_model = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
        "\n",
        "# Freeze base layers (initial training)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add classification head\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "output = Dense(y_cat.shape[1], activation=\"softmax\")(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "OTPLRwkPEGRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First stage of training!!! with frozen base\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "zoQTpQbVEMEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning! Unfreezing the layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile (lower learning rate helps prevent overfitting)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fine-tune\n",
        "history_fine = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "3WQ8uOT6EW4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the classification report\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get model predictions (one-hot to class index)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
        "y_true_labels = le.inverse_transform(np.argmax(y_test, axis=1))"
      ],
      "metadata": {
        "id": "Iq7nC-18FlBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a standard precision/recall/F1 report\n",
        "print(classification_report(y_true_labels, y_pred_labels))"
      ],
      "metadata": {
        "id": "vxXSLbh5Fp0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=le.classes_)\n",
        "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
        "\n",
        "# Plot confusion matrix as heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix — Image Classifier\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c8SjsdpfFr_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving a model\n",
        "\n",
        "model.save(\"image_classifier_model.h5\")\n",
        "# model.save(\"image_classifier_model.keras\")  # TensorFlow 2.11+\n",
        "\n",
        "# Saving the encoder\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)"
      ],
      "metadata": {
        "id": "EBWf65kALDwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reloading a model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"image_classifier_model.h5\")\n",
        "\n",
        "# Reloading the encoder\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# PRedict on new image\n",
        "\n",
        "# Load, preprocess, and predict\n",
        "img = Image.open(\"path_or_url_to_image\").convert(\"RGB\").resize((224, 224))\n",
        "arr = preprocess_input(np.expand_dims(np.array(img), axis=0))\n",
        "\n",
        "pred = model.predict(arr)\n",
        "predicted_class = le.inverse_transform([np.argmax(pred)])\n",
        "print(\"Predicted type:\", predicted_class[0])"
      ],
      "metadata": {
        "id": "5YFYT1SzLMf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "StaganJ8Fy_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise, train two models, one for text and one for images, to classify images on the \"culture\" tag\n",
        "\n",
        "**Help**, maybe it's better to clean the culture tag and take only the first part"
      ],
      "metadata": {
        "id": "omN_uubqHAyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(df_filt15k[\"culture\"])))"
      ],
      "metadata": {
        "id": "eBaeeVppIYA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_culture(text):\n",
        "    text = text.lower()\n",
        "    text = text.split(\",\")[0]\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # regex to remove non alphanumeric ch\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df_filt15k[\"clean_culture\"] = df_filt15k[\"culture\"].apply(clean_culture)"
      ],
      "metadata": {
        "id": "8M1IrC6oIxrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(df_filt15k[\"clean_culture\"])))"
      ],
      "metadata": {
        "id": "da-aqYs5JSrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: take the top 30 cultures and make a dataframe filtered with those\n",
        "# Step 2: train a text classifier based on the cleaned descriptions to classify\n",
        "# the cultures\n",
        "# Step 3: make a classification report on it and a confusion matrix\n",
        "# Step 4: extract a subset of images from the df (around 500) and fit them\n",
        "# to a model for image classification\n",
        "# Step 5: fine tune MobileNetV2 to classify images based on culture\n",
        "# Step 6: make a classification report on it and a confusion matrix"
      ],
      "metadata": {
        "id": "KiMCoC54JXI4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}